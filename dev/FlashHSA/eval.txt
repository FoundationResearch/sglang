[INFO|/root/VeOmni/veomni/ops/__init__.py:50] 01/20/2026 16:33:23 >> ✅ VeOmni ops patch applied.
[INFO|/root/VeOmni/veomni/__init__.py:32] 01/20/2026 16:33:23 >> ❌ veomni_patch is not available
[INFO|/root/VeOmni/veomni/__init__.py:34] 01/20/2026 16:33:23 >> 
========== Environment Variables ==========
MODELING_BACKEND=veomni (source=default)
USE_GROUP_GEMM=1 (source=default)
USE_LIGER_KERNEL=1 (source=default)
===========================================
[INFO|/root/VeOmni/veomni/__init__.py:35] 01/20/2026 16:33:23 >> 
=========== OPS ============
_fused_moe_forward = group_gemm_fused_moe_forward
_flash_attention_forward = transformers_flash_attention_forward
_cross_entropy = fused_liger_kernel_cross_entropy
==============================
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:59] 01/20/2026 16:33:26 >> Process_group timeout: None
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:59] 01/20/2026 16:33:26 >> Process_group timeout: None
[INFO|/root/VeOmni/veomni/utils/arguments.py:622] 01/20/2026 16:33:26 >> Set gradient accumulation to 1.
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:63] 01/20/2026 16:33:26 >> Process rank: 1, world size: 2
[WARNING|/root/VeOmni/veomni/utils/checkpoint_utils.py:81] 01/20/2026 16:33:26 >> Provided checkpoint path does not exist!
[WARNING|/root/VeOmni/veomni/utils/checkpoint_utils.py:107] 01/20/2026 16:33:26 >> Failed to find latest checkpoint path, will start training from step 0...
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:63] 01/20/2026 16:33:26 >> Process rank: 0, world size: 2
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:64] 01/20/2026 16:33:26 >> {
  "model": {
    "config_path": "configs/swan_gpt_tiny/config_rope_full_theta10000.json",
    "model_path": null,
    "tokenizer_path": "configs/olmo3_vocab",
    "foundation": {},
    "encoders": {},
    "decoders": {},
    "input_encoder": "encoder",
    "output_encoder": "decoder",
    "encode_target": false,
    "attn_implementation": "flash_attention_3",
    "moe_implementation": null,
    "basic_modules": []
  },
  "data": {
    "train_path": "/apdcephfs_sh8/share_300719895/shared/data/dolma3_mix-6T-1025-partial-tokenized/",
    "train_size": 10000000000,
    "data_type": "numpy",
    "dataloader_type": "native",
    "datasets_type": "olmo3",
    "multisource_datasets_type": "interleave",
    "enable_multisource": false,
    "source_name": null,
    "data_tag": "default",
    "drop_resume_buffer": false,
    "text_keys": "text",
    "image_keys": "images",
    "chat_template": "default",
    "max_seq_len": 8192,
    "num_workers": 2,
    "prefetch_factor": 2,
    "drop_last": true,
    "pin_memory": true,
    "shuffle_shard_nums": 1,
    "split_nums": 1,
    "predownload_factor": 0.5,
    "silent_exception": false
  },
  "train": {
    "output_dir": "../checkpoints/full-attn-rope-theta10000-tiny-olmo3pt-8K-noliger-debug",
    "vit_lr": 5e-05,
    "train_architecture": "full",
    "lr": 0.0003,
    "lr_min": 3e-05,
    "lr_start": 0.0,
    "weight_decay": 0.1,
    "no_decay_modules": [],
    "no_decay_params": [],
    "optimizer": "adamw",
    "max_grad_norm": 1.0,
    "micro_batch_size": 1,
    "global_batch_size": 2,
    "num_train_epochs": 1,
    "rmpad": false,
    "rmpad_with_pos_ids": false,
    "dyn_bsz": true,
    "dyn_bsz_margin": 0,
    "dyn_bsz_runtime": "worker",
    "dyn_bsz_buffer_size": 200,
    "bsz_warmup_ratio": 0.007,
    "bsz_warmup_init_mbtoken": 200,
    "lr_warmup_ratio": 0.01,
    "lr_decay_style": "cosine",
    "lr_decay_ratio": 1.0,
    "enable_mixed_precision": true,
    "enable_gradient_checkpointing": true,
    "enable_reentrant": false,
    "enable_full_shard": true,
    "enable_forward_prefetch": true,
    "enable_fsdp_offload": false,
    "enable_activation_offload": false,
    "activation_gpu_limit": 0.0,
    "init_device": "meta",
    "broadcast_model_weights_from_rank0": true,
    "enable_full_determinism": false,
    "empty_cache_steps": 500,
    "gc_steps": 500,
    "data_parallel_mode": "fsdp2",
    "data_parallel_replicate_size": 1,
    "data_parallel_shard_size": 2,
    "tensor_parallel_size": 1,
    "expert_parallel_size": 1,
    "ep_outside": false,
    "pipeline_parallel_size": 1,
    "ulysses_parallel_size": 1,
    "context_parallel_size": 1,
    "ckpt_manager": "dcp",
    "save_async": false,
    "load_checkpoint_path": null,
    "save_steps": 10000,
    "save_epochs": 1,
    "save_hf_weights": true,
    "seed": 42,
    "enable_compile": false,
    "use_wandb": false,
    "wandb_project": "FullAttnBaseline",
    "wandb_name": null,
    "enable_profiling": false,
    "profile_start_step": 1,
    "profile_end_step": 2,
    "profile_trace_dir": "./trace",
    "profile_record_shapes": true,
    "profile_profile_memory": true,
    "profile_with_stack": true,
    "profile_rank0_only": true,
    "max_steps": 30000,
    "async_enabled": false
  }
}
[WARNING|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/VeOmni/.venv/lib/python3.11/site-packages/transformers/utils/logging.py:328] 01/20/2026 16:33:26 >> Recommend to use hdfs path or hdfs_fuse path as the output path.
[INFO|/root/VeOmni/veomni/distributed/parallel_state.py:479] 01/20/2026 16:33:26 >> Initializing parallel state... dp_size 2, dp_replicate_size 1, dp_shard_size 2,tp_size 1, pp_size 1, ep_size 1, cp_size 1, ulysses_size 1
[INFO|/root/VeOmni/veomni/distributed/parallel_state.py:550] 01/20/2026 16:33:26 >> Device mesh: DeviceMesh('cuda', [0, 1], mesh_dim_names=('dp_shard',))
[INFO|/root/VeOmni/veomni/distributed/parallel_state.py:551] 01/20/2026 16:33:26 >> EP FSDP device mesh: None
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:87] 01/20/2026 16:33:26 >> Prepare data
LazyChunkedLoader: Loading /apdcephfs_sh8/share_300719895/shared/data/dolma3_mix-6T-1025-partial-tokenized/
LazyChunkedLoader: Loading /apdcephfs_sh8/share_300719895/shared/data/dolma3_mix-6T-1025-partial-tokenized/
total documents: 1852, total tokens:149720868123total documents: 1852, total tokens:149720868123

[WARNING|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/VeOmni/.venv/lib/python3.11/site-packages/transformers/utils/logging.py:328] 01/20/2026 16:33:27 >> Set train_steps to 30000. It should be for debug purpose only.
[WARNING|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/VeOmni/.venv/lib/python3.11/site-packages/transformers/utils/logging.py:328] 01/20/2026 16:33:27 >> Set train_steps to 30000. It should be for debug purpose only.
[INFO|/root/VeOmni/veomni/data/data_loader.py:89] 01/20/2026 16:33:27 >> train_steps: 30000, max_seq_len: 8192, use_rmpad: False, bsz_warmup_steps: 210, bsz_warmup_init_mbtoken: 200, token_micro_bsz: 8192, num_micro_batch: 1, micro_batch_size: 1, global_batch_size: 2, dp_size: 2, sp_size: 1.
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:142] 01/20/2026 16:33:27 >> Prepare model
[INFO|/root/VeOmni/veomni/models/loader.py:71] 01/20/2026 16:33:27 >> [CONFIG] Loading swangpt from custom config.
[INFO|/root/VeOmni/veomni/models/loader.py:199] 01/20/2026 16:33:27 >> Loading model from customized modeling.
init_device: meta
empty_init: True
weights_path: None
[INFO|/root/VeOmni/veomni/models/loader.py:209] 01/20/2026 16:33:27 >> Init empty model on meta device from config without init_weights.
self.inv_freq: tensor([1.0000e+00, 8.6596e-01, 7.4989e-01, 6.4938e-01, 5.6234e-01, 4.8697e-01,
        4.2170e-01, 3.6517e-01, 3.1623e-01, 2.7384e-01, 2.3714e-01, 2.0535e-01,
        1.7783e-01, 1.5399e-01, 1.3335e-01, 1.1548e-01, 1.0000e-01, 8.6596e-02,
        7.4989e-02, 6.4938e-02, 5.6234e-02, 4.8697e-02, 4.2170e-02, 3.6517e-02,
        3.1623e-02, 2.7384e-02, 2.3714e-02, 2.0535e-02, 1.7783e-02, 1.5399e-02,
        1.3335e-02, 1.1548e-02, 1.0000e-02, 8.6596e-03, 7.4989e-03, 6.4938e-03,
        5.6234e-03, 4.8697e-03, 4.2170e-03, 3.6517e-03, 3.1623e-03, 2.7384e-03,
        2.3714e-03, 2.0535e-03, 1.7783e-03, 1.5399e-03, 1.3335e-03, 1.1548e-03,
        1.0000e-03, 8.6596e-04, 7.4989e-04, 6.4938e-04, 5.6234e-04, 4.8697e-04,
        4.2170e-04, 3.6517e-04, 3.1623e-04, 2.7384e-04, 2.3714e-04, 2.0535e-04,
        1.7783e-04, 1.5399e-04, 1.3335e-04, 1.1548e-04]), tensor([[[1.0000e+00],
         [8.6596e-01],
         [7.4989e-01],
         [6.4938e-01],
         [5.6234e-01],
         [4.8697e-01],
         [4.2170e-01],
         [3.6517e-01],
         [3.1623e-01],
         [2.7384e-01],
         [2.3714e-01],
         [2.0535e-01],
         [1.7783e-01],
         [1.5399e-01],
         [1.3335e-01],
         [1.1548e-01],
         [1.0000e-01],
         [8.6596e-02],
         [7.4989e-02],
         [6.4938e-02],
         [5.6234e-02],
         [4.8697e-02],
         [4.2170e-02],
         [3.6517e-02],
         [3.1623e-02],
         [2.7384e-02],
         [2.3714e-02],
         [2.0535e-02],
         [1.7783e-02],
         [1.5399e-02],
         [1.3335e-02],
         [1.1548e-02],
         [1.0000e-02],
         [8.6596e-03],
         [7.4989e-03],
         [6.4938e-03],
         [5.6234e-03],
         [4.8697e-03],
         [4.2170e-03],
         [3.6517e-03],
         [3.1623e-03],
         [2.7384e-03],
         [2.3714e-03],
         [2.0535e-03],
         [1.7783e-03],
         [1.5399e-03],
         [1.3335e-03],
         [1.1548e-03],
         [1.0000e-03],
         [8.6596e-04],
         [7.4989e-04],
         [6.4938e-04],
         [5.6234e-04],
         [4.8697e-04],
         [4.2170e-04],
         [3.6517e-04],
         [3.1623e-04],
         [2.7384e-04],
         [2.3714e-04],
         [2.0535e-04],
         [1.7783e-04],
         [1.5399e-04],
         [1.3335e-04],
         [1.1548e-04]]])self.inv_freq: tensor([1.0000e+00, 8.6596e-01, 7.4989e-01, 6.4938e-01, 5.6234e-01, 4.8697e-01,
        4.2170e-01, 3.6517e-01, 3.1623e-01, 2.7384e-01, 2.3714e-01, 2.0535e-01,
        1.7783e-01, 1.5399e-01, 1.3335e-01, 1.1548e-01, 1.0000e-01, 8.6596e-02,
        7.4989e-02, 6.4938e-02, 5.6234e-02, 4.8697e-02, 4.2170e-02, 3.6517e-02,
        3.1623e-02, 2.7384e-02, 2.3714e-02, 2.0535e-02, 1.7783e-02, 1.5399e-02,
        1.3335e-02, 1.1548e-02, 1.0000e-02, 8.6596e-03, 7.4989e-03, 6.4938e-03,
        5.6234e-03, 4.8697e-03, 4.2170e-03, 3.6517e-03, 3.1623e-03, 2.7384e-03,
        2.3714e-03, 2.0535e-03, 1.7783e-03, 1.5399e-03, 1.3335e-03, 1.1548e-03,
        1.0000e-03, 8.6596e-04, 7.4989e-04, 6.4938e-04, 5.6234e-04, 4.8697e-04,
        4.2170e-04, 3.6517e-04, 3.1623e-04, 2.7384e-04, 2.3714e-04, 2.0535e-04,
        1.7783e-04, 1.5399e-04, 1.3335e-04, 1.1548e-04]), tensor([[[1.0000e+00],
         [8.6596e-01],
         [7.4989e-01],
         [6.4938e-01],
         [5.6234e-01],
         [4.8697e-01],
         [4.2170e-01],
         [3.6517e-01],
         [3.1623e-01],
         [2.7384e-01],
         [2.3714e-01],
         [2.0535e-01],
         [1.7783e-01],
         [1.5399e-01],
         [1.3335e-01],
         [1.1548e-01],
         [1.0000e-01],
         [8.6596e-02],
         [7.4989e-02],
         [6.4938e-02],
         [5.6234e-02],
         [4.8697e-02],
         [4.2170e-02],
         [3.6517e-02],
         [3.1623e-02],
         [2.7384e-02],
         [2.3714e-02],
         [2.0535e-02],
         [1.7783e-02],
         [1.5399e-02],
         [1.3335e-02],
         [1.1548e-02],
         [1.0000e-02],
         [8.6596e-03],
         [7.4989e-03],
         [6.4938e-03],
         [5.6234e-03],
         [4.8697e-03],
         [4.2170e-03],
         [3.6517e-03],
         [3.1623e-03],
         [2.7384e-03],
         [2.3714e-03],
         [2.0535e-03],
         [1.7783e-03],
         [1.5399e-03],
         [1.3335e-03],
         [1.1548e-03],
         [1.0000e-03],
         [8.6596e-04],
         [7.4989e-04],
         [6.4938e-04],
         [5.6234e-04],
         [4.8697e-04],
         [4.2170e-04],
         [3.6517e-04],
         [3.1623e-04],
         [2.7384e-04],
         [2.3714e-04],
         [2.0535e-04],
         [1.7783e-04],
         [1.5399e-04],
         [1.3335e-04],
         [1.1548e-04]]])

inv freq before build parallel: tensor([1.0000e+00, 8.6596e-01, 7.4989e-01, 6.4938e-01, 5.6234e-01, 4.8697e-01,
        4.2170e-01, 3.6517e-01, 3.1623e-01, 2.7384e-01, 2.3714e-01, 2.0535e-01,
        1.7783e-01, 1.5399e-01, 1.3335e-01, 1.1548e-01, 1.0000e-01, 8.6596e-02,
        7.4989e-02, 6.4938e-02, 5.6234e-02, 4.8697e-02, 4.2170e-02, 3.6517e-02,
        3.1623e-02, 2.7384e-02, 2.3714e-02, 2.0535e-02, 1.7783e-02, 1.5399e-02,
        1.3335e-02, 1.1548e-02, 1.0000e-02, 8.6596e-03, 7.4989e-03, 6.4938e-03,
        5.6234e-03, 4.8697e-03, 4.2170e-03, 3.6517e-03, 3.1623e-03, 2.7384e-03,
        2.3714e-03, 2.0535e-03, 1.7783e-03, 1.5399e-03, 1.3335e-03, 1.1548e-03,
        1.0000e-03, 8.6596e-04, 7.4989e-04, 6.4938e-04, 5.6234e-04, 4.8697e-04,
        4.2170e-04, 3.6517e-04, 3.1623e-04, 2.7384e-04, 2.3714e-04, 2.0535e-04,
        1.7783e-04, 1.5399e-04, 1.3335e-04, 1.1548e-04])inv freq before build parallel: tensor([1.0000e+00, 8.6596e-01, 7.4989e-01, 6.4938e-01, 5.6234e-01, 4.8697e-01,
        4.2170e-01, 3.6517e-01, 3.1623e-01, 2.7384e-01, 2.3714e-01, 2.0535e-01,
        1.7783e-01, 1.5399e-01, 1.3335e-01, 1.1548e-01, 1.0000e-01, 8.6596e-02,
        7.4989e-02, 6.4938e-02, 5.6234e-02, 4.8697e-02, 4.2170e-02, 3.6517e-02,
        3.1623e-02, 2.7384e-02, 2.3714e-02, 2.0535e-02, 1.7783e-02, 1.5399e-02,
        1.3335e-02, 1.1548e-02, 1.0000e-02, 8.6596e-03, 7.4989e-03, 6.4938e-03,
        5.6234e-03, 4.8697e-03, 4.2170e-03, 3.6517e-03, 3.1623e-03, 2.7384e-03,
        2.3714e-03, 2.0535e-03, 1.7783e-03, 1.5399e-03, 1.3335e-03, 1.1548e-03,
        1.0000e-03, 8.6596e-04, 7.4989e-04, 6.4938e-04, 5.6234e-04, 4.8697e-04,
        4.2170e-04, 3.6517e-04, 3.1623e-04, 2.7384e-04, 2.3714e-04, 2.0535e-04,
        1.7783e-04, 1.5399e-04, 1.3335e-04, 1.1548e-04])


inv freq after build parallel: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:1')inv freq after build parallel: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0')

[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:251] 01/20/2026 16:33:30 >> rank1 Start training, train_steps: 30000, epochs: 1
[INFO|/apdcephfs_fsgm/share_303843174/user/shawnxxxhu/FlashHSA/tasks/replay.py:251] 01/20/2026 16:33:30 >> rank0 Start training, train_steps: 30000, epochs: 1
[INFO|/root/VeOmni/veomni/utils/helper.py:554] 01/20/2026 16:33:31 >> [rank 1]: input_ids's shape: torch.Size([1, 8192]), device: cpu, tensor([[  369, 58011,  7978,  ...,   358,  5463,   596]], dtype=torch.int32)
[INFO|/root/VeOmni/veomni/utils/helper.py:554] 01/20/2026 16:33:31 >> [rank 1]: attention_mask's shape: torch.Size([1, 8192]), device: cpu, tensor([[1, 1, 1,  ..., 1, 1, 1]])
[INFO|/root/VeOmni/veomni/utils/helper.py:554] 01/20/2026 16:33:31 >> [rank 1]: labels's shape: torch.Size([1, 8192]), device: cpu, tensor([[  369, 58011,  7978,  ...,   358,  5463,   596]], dtype=torch.int32)
[INFO|/root/VeOmni/veomni/utils/helper.py:554] 01/20/2026 16:33:31 >> [rank 0]: input_ids's shape: torch.Size([1, 8192]), device: cpu, tensor([[ 358,  990,  389,  ..., 4194,    8, 1174]], dtype=torch.int32)
[INFO|/root/VeOmni/veomni/utils/helper.py:554] 01/20/2026 16:33:31 >> [rank 0]: attention_mask's shape: torch.Size([1, 8192]), device: cpu, tensor([[1, 1, 1,  ..., 1, 1, 1]])
[INFO|/root/VeOmni/veomni/utils/helper.py:554] 01/20/2026 16:33:31 >> [rank 0]: labels's shape: torch.Size([1, 8192]), device: cpu, tensor([[ 358,  990,  389,  ..., 4194,    8, 1174]], dtype=torch.int32)
position ids: tensor([[   0,    1,    2,  ..., 8189, 8190, 8191]], device='cuda:1')
position ids: tensor([[   0,    1,    2,  ..., 8189, 8190, 8191]], device='cuda:0')
self.inv_freq: tensor([[[0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.]]], device='cuda:1')
fwd: pos_ids: tensor([[   0,    1,    2,  ..., 8189, 8190, 8191]], device='cuda:1')
self.inv_freq: tensor([[[0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.]]], device='cuda:0')
fwd: pos_ids: tensor([[   0,    1,    2,  ..., 8189, 8190, 8191]], device='cuda:0')
inv_freq: tensor([[[0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.]]], device='cuda:1')
inv_freq: tensor([[[0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.],
         [0.]]], device='cuda:0')
position embs1: (tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:1',
       dtype=torch.bfloat16), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1',
       dtype=torch.bfloat16))
position embs1: (tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',
       dtype=torch.bfloat16), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',
       dtype=torch.bfloat16))
position embs2: (tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:1',
       dtype=torch.bfloat16), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1',
       dtype=torch.bfloat16))
position embs2: (tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',
       dtype=torch.bfloat16), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',
       dtype=torch.bfloat16))
cos: tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',
       dtype=torch.bfloat16), sin: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',
       dtype=torch.bfloat16)
cos: tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:1',
       dtype=torch.bfloat16), sin: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:1',
       dtype=torch.bfloat16)
